{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_chatbot",
      "provenance": [],
      "authorship_tag": "ABX9TyMNoNrolPsTbNfFO0PSpMIE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrevinWacker/NLP-practice/blob/main/nlp_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HU1yvMZVaRG"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import nltk\r\n",
        "import spacy\r\n",
        "import re\r\n",
        "import random\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "from sqlalchemy import create_engine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvOfTZa4W6Ct",
        "outputId": "92812fa9-4589-4eea-9838-b9172d41263a"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZzab1geYSpE"
      },
      "source": [
        "Cornell Movie Dialogue\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecNcRcsbXNxk"
      },
      "source": [
        "postgres_user = 'dsbc_student'\r\n",
        "postgres_pw = '7*.8G9QH21'\r\n",
        "postgres_host = '142.93.121.174'\r\n",
        "postgres_port = '5432'\r\n",
        "postgres_db = 'cornell_movie_dialogs'\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\r\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\r\n",
        "\r\n",
        "\r\n",
        "movies_df = pd.read_sql_query('SELECT * FROM dialogs',con=engine)\r\n",
        "\r\n",
        "engine.dispose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drcQjyGnI7-Z",
        "outputId": "241d2cd8-4f5f-4ac1-e437-88a69141703a"
      },
      "source": [
        "movies_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 304446 entries, 0 to 304445\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   index    304446 non-null  int64 \n",
            " 1   dialogs  304446 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 4.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld2_w-_cIq3C"
      },
      "source": [
        "# Limiting due to memory issues\r\n",
        "# movies_df = movies_df.loc[:200000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bucvyIrF_nw9"
      },
      "source": [
        "# Create spacy object to get text from DataFrame\r\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\r\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\r\n",
        "\r\n",
        "# This allows for more characters to be stored than what's allowed as default\r\n",
        "nlp.max_length = 20000000\r\n",
        "\r\n",
        "# Get quotes out of the dialog feature in the DataFrame\r\n",
        "quotes = nlp(\" \".join(movies_df.dialogs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKVLsTbbSnPW",
        "outputId": "32096a6e-cb5f-41d5-bb2e-62bbb9a0df2a"
      },
      "source": [
        "# Initial analysis\r\n",
        "print(\"'quotes' is a {} object.\".format(type(quotes)))\r\n",
        "print(\"It is {} tokens long\".format(len(quotes)))\r\n",
        "print(\"The first one hundred tokens are '{}'\".format(quotes[:100]))\r\n",
        "print(\"The type of each token is {}\".format(type(quotes[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'quotes' is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 2784977 tokens long\n",
            "The first one hundred tokens are 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again. Well, I thought we'd start with pronunciation, if that's okay with you. Not the hacking and gagging and spitting part.  Please. Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? You're asking me out.  That's so cute. What's your name again? Forget it. No, no, it'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAC6a2CkTqgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913f6194-ae09-4219-83da-17bb0fdc3b30"
      },
      "source": [
        "# Get sentences from quotes to act as training data\r\n",
        "quotes_sents = [sent.text for sent in quotes.sents if len(sent.text) > 1]\r\n",
        "\r\n",
        "quotes_sents[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Can we make this quick?',\n",
              " ' Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.',\n",
              " ' Again.',\n",
              " \"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n",
              " 'Not the hacking and gagging and spitting part.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1h0MWkwLwq7"
      },
      "source": [
        "# Develop a chatbot using this corpus. In doing this, you're free to choose a chatbot development library like ChatterBot or write your own code from scratch.\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L1FDGH_MDUJ"
      },
      "source": [
        "I'm going to do both for the sake of practice, starting with the self made one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMkx4TJyLv_2"
      },
      "source": [
        "# Starting with greetings\r\n",
        "\r\n",
        "greetings_input = [\"hello\", \"hi\", \"greetings\", \"sup\", \"yo dawg\", \"oh hi\", \"hola\"]\r\n",
        "greetings_output = [\"hello to you\", \"oh hi\", \"hi, thanks for chatting\", \"Bonjour! (Practicing my French)\", \"greetings\"]\r\n",
        "\r\n",
        "def greeting(user_input):\r\n",
        "  for word in user_input.split():\r\n",
        "    if word.lower() in greetings_input:\r\n",
        "      return random.choice(greetings_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojlOPnxCNm-m"
      },
      "source": [
        "def user_input(user_text):\r\n",
        "\r\n",
        "  # Establish a response as a string\r\n",
        "  response = \"\"\r\n",
        "\r\n",
        "  # Apply spaCy to user_input and add sentences to the larger corpus\r\n",
        "  user_response = nlp(user_text) #Defined later\r\n",
        "  user_sents = [sent.text for sent in user_response.sents]\r\n",
        "\r\n",
        "  # Add sentences to larger corpus\r\n",
        "  for sent in user_sents:\r\n",
        "    quotes_sents.append(sent)\r\n",
        "\r\n",
        "  # Vectorize new complete corpus and transform\r\n",
        "  vectorizer = TfidfVectorizer()\r\n",
        "  new_vec = vectorizer.fit_transform(quotes_sents)\r\n",
        "  # Remove user input, to avoid it becoming a response down the line\r\n",
        "  quotes_sents.pop(-1)\r\n",
        "\r\n",
        "  # Calculate cosine similarity between user input & other sentences\r\n",
        "  cosine_similarities = cosine_similarity(new_vec[-1],new_vec[:-1])\r\n",
        "\r\n",
        "  # Get an index of the most similar sentence to be used as a response\r\n",
        "  indx = np.argmax(cosine_similarities)\r\n",
        "  response = \"\" + quotes_sents[indx]\r\n",
        "  return response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbP-ymGnQEGA",
        "outputId": "51360da9-7ffc-46d3-8389-da789ab92dc8"
      },
      "source": [
        "# Create chatbot object\r\n",
        "print(\"Chatbot: Bonjour!  Thanks for chatting with me.\")\r\n",
        "\r\n",
        "while(True):\r\n",
        "\r\n",
        "  user_text = input(\"User: \")\r\n",
        "  # Turn into lowercase to avoid mismatch\r\n",
        "  user_text = user_text.lower()\r\n",
        "\r\n",
        "  goodbye_input = [\"bye\", \"i'm leaving\", \"see ya\", \"a demain\", \"i have to go\", \"goodbye\"]\r\n",
        "  goodbye_output = [\"ok, goodbye\", \"goodbye, come back soon\", \"goodbyeeeeeeee\"]\r\n",
        "\r\n",
        "  greeting(user_text)\r\n",
        "\r\n",
        "  if user_text not in goodbye_input:\r\n",
        "\r\n",
        "    if greeting(user_text) != None:\r\n",
        "      print(\"Chatbot: {}\".format(greeting(user_text)))\r\n",
        "    else:\r\n",
        "      print(\"Chatbot: {}\".format(user_input(user_text)))\r\n",
        "  \r\n",
        "  else:\r\n",
        "    print(\"Chatbot: {}\".format(random.choice(goodbye_output)))\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chatbot: Bonjour!  Thanks for chatting with me.\n",
            "User: Hello\n",
            "Chatbot: hello to you\n",
            "User: Hi\n",
            "Chatbot: hi, thanks for chatting\n",
            "User: Bonjour\n",
            "Chatbot: Bonjour?\n",
            "User: Yes, it's French\n",
            "Chatbot: French?\n",
            "User: French is the language of France, are you familiar\n",
            "Chatbot: Yeah, French guys from France.\n",
            "User: Yes!  French men tend to be very attractive\n",
            "Chatbot: Very attractive.\n",
            "User: I appreciate the agreement!  How are you today?\n",
            "Chatbot: How are you today?\n",
            "User: I'm good, but I'm hoping my chatbot improves its performance\n",
            "Chatbot: But I'm hoping.\n",
            "User: What are you hoping for?\n",
            "Chatbot: What are you, hoping?\n",
            "User: Yes I am.  I told you.  Please listen actively to me\n",
            "Chatbot: Please listen to me.\n",
            "User: I am!  You're getting kind of rude with me\n",
            "Chatbot: You're rude . . .\n",
            "User: Wow!  I'm leaving\n",
            "Chatbot: I'm leaving!\n",
            "User: You can't, you're on a computer, there's nowhere for you to go!\n",
            "Chatbot: There's nowhere else for it to go.\n",
            "User: Exactly\n",
            "Chatbot: Exactly.\n",
            "User: Anyway, I need to try to make a better chatbot so we have to cut our conversation short now\n",
            "Chatbot:  You don't have to make conversation with me.\n",
            "User: Ok, well I hope you have a good rest of the day.  Overall I think you were nice to talk with\n",
            "Chatbot: Overall - pretty good.\n",
            "User: Yes\n",
            "Chatbot: Yes.\n",
            "User: I have to go\n",
            "Chatbot: goodbyeeeeeeee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbyW_FjvY1uy"
      },
      "source": [
        "--- \r\n",
        "The chatbot does ok.  The French discussion is somewhat coherent and there is some direct matching for simple user inputs (how are you today, I'm leaving, etc.).  You can tell that there's an emphasis on matching, vs having an appopriate reaction.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqKTaYb0kpqW"
      },
      "source": [
        "Chatterbot model\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibeWZmrLksnn",
        "outputId": "baa8862a-ae62-4563-b08e-ad2e4730b1e1"
      },
      "source": [
        "!pip install chatterbot\r\n",
        "!pip install chatterbot corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chatterbot in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2.8.1)\n",
            "Requirement already satisfied: mathparse<0.2,>=0.1 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (0.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied: sqlalchemy<1.4,>=1.3 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (1.3.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
            "Requirement already satisfied: chatterbot in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Collecting corpus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/b9/120d9e0ae8702a6929946b494b723a4de6c9bf3d79e8e07e239a81be4e7c/Corpus-0.4.2.tar.gz (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy<1.4,>=1.3 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (1.3.23)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied: mathparse<0.2,>=0.1 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
            "Building wheels for collected packages: corpus\n",
            "  Building wheel for corpus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for corpus: filename=Corpus-0.4.2-cp36-none-any.whl size=88799 sha256=b8fc6f5cba0b34bfdd94dde090d094cd7c3b210f56a8dff2f424badc95147627\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/20/6d/214e9c84ce43f62538d4c2f6e23d412bf9a52dd0f12bc716c9\n",
            "Successfully built corpus\n",
            "Installing collected packages: corpus\n",
            "Successfully installed corpus-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp40vkGgky_S",
        "outputId": "1dbdfaf7-610a-42c5-938b-9507e895812e"
      },
      "source": [
        "from chatterbot import ChatBot\r\n",
        "from chatterbot.trainers import ListTrainer\r\n",
        "\r\n",
        "# Use dialogs as vocabulary\r\n",
        "chatbot = ChatBot('quotes')\r\n",
        "chatbot.storage.drop()\r\n",
        "\r\n",
        "listtrainer = ListTrainer(chatbot).train(quotes_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXm0fz2ulwAr",
        "outputId": "03bdd340-72bc-4a95-ce77-0ac89543a1a1"
      },
      "source": [
        "# Try the ChatterBot bot\r\n",
        "print(\"Chatbot: Bonjour!  Thanks for chatting with me.\")\r\n",
        "\r\n",
        "while(True):\r\n",
        "\r\n",
        "  user_text = input(\"User: \")\r\n",
        "  # Turn into lowercase to avoid mismatch\r\n",
        "  user_text = user_text.lower()\r\n",
        "\r\n",
        "  goodbye_input = [\"bye\", \"i'm leaving\", \"see ya\", \"a demain\", \"i have to go\", \"goodbye\"]\r\n",
        "  goodbye_output = [\"ok, goodbye\", \"goodbye, come back soon\", \"goodbyeeeeeeee\"]\r\n",
        "\r\n",
        "  greeting(user_text)\r\n",
        "\r\n",
        "  if user_text not in goodbye_input:\r\n",
        "\r\n",
        "    if greeting(user_text) != None:\r\n",
        "      print(\"Chatbot: {}\".format(greeting(user_text)))\r\n",
        "    else:\r\n",
        "      print(\"Chatbot: {}\".format(chatbot.get_response(user_text)))\r\n",
        "  \r\n",
        "  else:\r\n",
        "    print(\"Chatbot: {}\".format(random.choice(goodbye_output)))\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chatbot: Bonjour!  Thanks for chatting with me.\n",
            "User: bonjour\n",
            "Chatbot: Monsieur?\n",
            "User: Oui, je suis un homme\n",
            "Chatbot: He understands.\n",
            "User: Are you the he?\n",
            "Chatbot: As a gentleman You're sweet.\n",
            "User: Why thank you!  I like to think that I'm pretty nice\n",
            "Chatbot: Eber's Deep Conditioner every two days.\n",
            "User: I don't usually wash my hair every time\n",
            "Chatbot: No.\n",
            "User: No what?\n",
            "Chatbot: No, I won't go with you Why not?\n",
            "User: I feel like you're sentence is running on a little too long\n",
            "Chatbot: Eber's Deep Conditioner every two days.\n",
            "User: I wonder why you said that\n",
            "Chatbot: Half is fair.\n",
            "User: This isn't quite as riveting a conversation as I had with my other chatbot.\n",
            "Chatbot: They convinced her to let them buy her a meal in the city.\n",
            "User: I didn't know chatbots could eat!\n",
            "Chatbot: Joey Dorsey?\n",
            "User: That's your name?\n",
            "Chatbot: Forget it.\n",
            "User: Ok\n",
            "Chatbot: Not the hacking and gagging and spitting part.\n",
            "User: Ask me a question\n",
            "Chatbot: Where were you planning to stay during the two weeks that you're here?\n",
            "User: I live here in Chicago!  I would love to plan on doing something though; the pandemic has really put a damper on my plans\n",
            "Chatbot: Did she actually say she'd go out with you?\n",
            "User: I don't date women\n",
            "Chatbot: It's just you.\n",
            "User: Bye\n",
            "Chatbot: ok, goodbye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwn-mQJQ4kjK"
      },
      "source": [
        "---\r\n",
        "\r\n",
        "This chatbot had a larger variety of responses than the self made one, though they weren't necessarily coherent.  There was also a repeated verse, which was given as a response to two very different user inputted text."
      ]
    }
  ]
}