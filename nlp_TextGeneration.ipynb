{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_TextGeneration",
      "provenance": [],
      "authorship_tag": "ABX9TyMLZFTvruwhnOCCYiuirKHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrevinWacker/NLP-practice/blob/main/nlp_TextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2CKVBBv7wBA",
        "outputId": "f27a5a7e-111d-468a-81ac-51d9822dfe24"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import nltk\r\n",
        "import spacy\r\n",
        "import re\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "from sqlalchemy import create_engine\r\n",
        "\r\n",
        "!pip install markovify\r\n",
        "import markovify"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: markovify in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from markovify) (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd6HCbvaV3yF"
      },
      "source": [
        "postgres_user = 'dsbc_student'\r\n",
        "postgres_pw = '7*.8G9QH21'\r\n",
        "postgres_host = '142.93.121.174'\r\n",
        "postgres_port = '5432'\r\n",
        "postgres_db = 'twitter_sentiment'\r\n",
        "\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\r\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\r\n",
        "\r\n",
        "\r\n",
        "twitter_df = pd.read_sql_query('SELECT * FROM twitter',con=engine)\r\n",
        "\r\n",
        "engine.dispose()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "_5iUL1_NWF8v",
        "outputId": "9a92ea68-abce-414e-8481-cd034f58ccff"
      },
      "source": [
        "twitter_df.head()\r\n",
        "# We're looking at feature \"text\" and we need to remove all of the @VirginAmerica at the beginning"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index            tweet_id  ... tweet_location               user_timezone\n",
              "0      0  570306133677760513  ...           None  Eastern Time (US & Canada)\n",
              "1      1  570301130888122368  ...           None  Pacific Time (US & Canada)\n",
              "2      2  570301083672813571  ...      Lets Play  Central Time (US & Canada)\n",
              "3      3  570301031407624196  ...           None  Pacific Time (US & Canada)\n",
              "4      4  570300817074462722  ...           None  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bucvyIrF_nw9"
      },
      "source": [
        "# Create spacy object to get text from DataFrame\r\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\r\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\r\n",
        "\r\n",
        "# This allows for more characters to be stored than what was initially allowed(?)\r\n",
        "nlp.max_length = 20000000"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5d5DnMsA20X",
        "outputId": "cd5bca45-1e82-4016-eb02-553ba44f8938"
      },
      "source": [
        "twitter_df[\"airline\"].unique()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Virgin America', 'United', 'American', 'Southwest', 'Delta',\n",
              "       'US Airways'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4__GcXbOAiZr"
      },
      "source": [
        "# Remove @ from all text threads; we already know the airline provider from the 'airline' feature\r\n",
        "for i in range(twitter_df.shape[0]):\r\n",
        "  twitter_df.loc[i,\"text\"] = re.sub(r'\\@VirginAmerica',\"\",twitter_df.loc[i,\"text\"])\r\n",
        "  twitter_df.loc[i,\"text\"] = re.sub(r'\\@AmericanAir',\"\",twitter_df.loc[i,\"text\"])\r\n",
        "  twitter_df.loc[i,\"text\"] = re.sub(r'\\@united',\"\",twitter_df.loc[i,\"text\"])\r\n",
        "  twitter_df.loc[i,\"text\"] = re.sub(r'\\@SouthwestAir',\"\",twitter_df.loc[i,\"text\"])\r\n",
        "  twitter_df.loc[i,\"text\"] = re.sub(r'\\@JetBlue',\"\",twitter_df.loc[i,\"text\"])\r\n",
        "  twitter_df.loc[i,\"text\"] = re.sub(r'\\@USAirways',\"\",twitter_df.loc[i,\"text\"])\r\n",
        "\r\n",
        "# Get quotes out of the text feature in the DataFrame\r\n",
        "tweets = nlp(\" \".join(twitter_df.text))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T9o2wYTXmio",
        "outputId": "e059d3ff-fe07-4ae6-da5a-d3a78971eaeb"
      },
      "source": [
        "# Complete some initial analysis\r\n",
        "print(\"'tweets' is a {} object.\".format(type(tweets)))\r\n",
        "print(\"It is {} tokens long\".format(len(tweets)))\r\n",
        "print(\"The first one hundred tokens are '{}'\".format(tweets[:100]))\r\n",
        "print(\"The type of each token is {}\".format(type(tweets[0])))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'tweets' is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 303253 tokens long\n",
            "The first one hundred tokens are 'What @dhepburn said. plus you've added commercials to the experience... tacky. I didn't today... Must mean I need to take another trip! it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse and it's a really big bad thing about it seriously would pay $30 a flight for seats that didn't have this playing.\n",
            "it's really the only bad thing about flying VA yes, nearly every time I fly VX this “ear worm'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvxlMmv-FbfY"
      },
      "source": [
        "# Create new class that delivers new sentences following correct grammatical structures\r\n",
        "\r\n",
        "class POSifiedText(markovify.Text):\r\n",
        "    \r\n",
        "    def word_split(self, sentence):\r\n",
        "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\r\n",
        "\r\n",
        "    def word_join(self, words):\r\n",
        "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\r\n",
        "        return sentence"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0NdiF8DC6RX"
      },
      "source": [
        "# Train a Markov chain model by using only the negative sentiment tweets. Generate some random sentences. Do the generated sentences exhibit the same negative sentiment?\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTswGu8SDBJ1",
        "outputId": "dc2e6803-7c11-431d-f4d7-9fb0c93d187c"
      },
      "source": [
        "# Get only negative tweets\r\n",
        "negative_tweets = nlp(\" \".join(twitter_df[twitter_df[\"airline_sentiment\"] == 'negative'].text))\r\n",
        "\r\n",
        "#Getting sentences with no punctuation or stopwords\r\n",
        "negative_tweets = [sent.text for sent in negative_tweets.sents if len(sent.text) > 1]\r\n",
        "\r\n",
        "negative_tweets[:4]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it\\'s really aggressive to blast obnoxious \"entertainment\" in your guests\\' faces &amp; they have little recourse and it\\'s a really big bad thing about it seriously would pay $30 a flight for seats that didn\\'t have this playing.',\n",
              " \"\\nit's really the only bad thing about flying VA SFO-PDX schedule is still MIA.\",\n",
              " \" I flew from NYC to SFO last week and couldn't fully sit in my seat due to two large gentleman on either side of me.\",\n",
              " 'HELP!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCULidQvEvi_",
        "outputId": "4c1c54b3-7538-40fb-ff18-805ec6d281f2"
      },
      "source": [
        "negative_sent_generator = POSifiedText(negative_tweets,state_size=3)\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  print(negative_sent_generator.make_sentence())\r\n",
        "  print()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "\n",
            "Every flight with you guys was the way to go   DTV does nt work , pilots Late Flight , div to phx & amp ; I 'm gon na ignore the fasten seatbelt sign and I want a confirmation !\n",
            "\n",
            "Despite all our efforts you did zero to keep her safe ..... alone on a flight tomorrow even though I had 1st class seat orig I have a simple question and the phone line does not even let me stay on hold ?\n",
            "\n",
            "Very frustrating and the gate is missing .\n",
            "\n",
            "I ca n't really afford another 4 hours now and still on tarmac .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM6vbbeSHu8v"
      },
      "source": [
        "The generated tweets aren't very coherent but they do show a negative sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1p76HwzIQK1"
      },
      "source": [
        "#Do the same generation but for all positive tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v5q2DoaIPrF",
        "outputId": "17f5cb1a-e370-4265-c302-fb35b2510aae"
      },
      "source": [
        "# Get only positive tweets\r\n",
        "positive_tweets = nlp(\" \".join(twitter_df[twitter_df[\"airline_sentiment\"] == 'positive'].text))\r\n",
        "\r\n",
        "#Getting sentences with no punctuation or stopwords\r\n",
        "positive_tweets = [sent.text for sent in positive_tweets.sents if len(sent.text) > 1]\r\n",
        "\r\n",
        "positive_tweets[:4]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"plus you've added commercials to the experience... tacky.\",\n",
              " \"yes, nearly every time I fly VX this “ear worm” won’t go away :) @virginamerica Well, I didn't…but NOW I DO!\",\n",
              " ':-D it was amazing, and arrived an hour early.',\n",
              " \"You're too good to me.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b71KPRR9IPrk",
        "outputId": "b476bd5d-73a6-4367-f85c-20b1f48bf0bf"
      },
      "source": [
        "positive_sent_generator = POSifiedText(positive_tweets,state_size=2)\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  print(positive_sent_generator.make_sentence(tries=50))\r\n",
        "  print()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "everything 's good to hear my bag not making it to San Antonio and your Twitter feed is clearly extremely useful .\n",
            "\n",
            "Love the concept of # DivadaPouch aka # ThePoopQueen http://t.co/XXY2d2iMnP   Once again , safety first ! !\n",
            "\n",
            "Already thinking about my 2nd trip to the T , realtime appreciation from JetBlue # rockingthetweets # JVMChat   @JayVig @roxydigital awww ^_^ R to the captain and crew !\n",
            "\n",
            "I look forward to my global first class on that flight by gate agent Jan L at Phoenix was at least !\n",
            "\n",
            "destinationdragons   that 's great .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSv9Tle-Jf7k"
      },
      "source": [
        "These tweets have an obvious general sentiment.  Also, adjusting the state_size to 2 produced more coherent tweets; this may be due to the compressed nature of tweets requiring more concise language so having only immediate surrounding words affecting text generation may be more helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ulU_Wu4J2aH"
      },
      "source": [
        "# Train on all tweets.\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4W9dMS0KqjA"
      },
      "source": [
        "tweets = [sent.text for sent in tweets.sents if len(sent.text) > 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVdjhh-pKCnO",
        "outputId": "a711efea-1017-46ee-dfe1-a74af2bf87fe"
      },
      "source": [
        "alltweets_sent_generator = POSifiedText(tweets,state_size=3)\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  print(alltweets_sent_generator.make_sentence())\r\n",
        "  print()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to Increase Charter Service to Cuba - # Travel Agent http://t.co/lYQrb4HCYU   you guys should re - read it .\n",
            "\n",
            "Need to be in California 5hrs ago   I need to change a flight   Delayed more and more these days .\n",
            "\n",
            "So when was I supposed to watch Scandal ?\n",
            "\n",
            "Hopefully the bag is , but we have WiFi – just saying .\n",
            "\n",
            "I am seriously tired of being treated this way particularly when I was sound asleep .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQe55uUGLHJZ"
      },
      "source": [
        "These all lean negative, which would either indicate there are more negative tweets in the entire dataset so we're more likely to see something negative, a lot of the data is mislabeled and we really just have a lot of negative tweets, or even positive tweets have a lot of negative/ambiguous language within them."
      ]
    }
  ]
}